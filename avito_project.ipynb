{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперимент 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика для сравнения - средняя ширина доверительного интервала при проведенных 1000 AA тестов. Тесты, которые будем сравнивать:\n",
    "\n",
    "1. T-test\n",
    "2. Bootstrap (центральный)\n",
    "3. Normed Bootstrap (центральный)\n",
    "4. Cuped\n",
    "\n",
    "Также выведем для каждого теста реально достигнутый уровень значимости. Давайте сначала реализуем каждый из тестов. \n",
    "\n",
    "Всюду $\\alpha = 0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import scipy.stats as sps\n",
    "import statsmodels.stats.api as sms\n",
    "import numpy as np\n",
    "\n",
    "ExperimentComparisonResults = namedtuple('ExperimentComparisonResults',\n",
    "                                        ['pvalue', 'effect', 'ci_length'])\n",
    "\n",
    "ExperimentComparisonResultsBootstrap = namedtuple('ExperimentComparisonResultsBootstrap',\n",
    "                                                ['effect_flag', 'effect', 'ci_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(test, control, alpha=0.05):\n",
    "    test_result = sms.CompareMeans(sms.DescrStatsW(test), sms.DescrStatsW(control))\n",
    "    left_bound, right_bound = test_result.tconfint_diff(alpha=alpha, alternative='two-sided', usevar='unequal')\n",
    "\n",
    "    ci_length = right_bound - left_bound\n",
    "    pvalue = sps.ttest_ind(test, control, equal_var=False).pvalue\n",
    "    effect = np.mean(test) - np.mean(control)\n",
    "    return ExperimentComparisonResults(pvalue, effect, ci_length)\n",
    "\n",
    "\n",
    "def cuped(control_before, test_before, control, test, alpha=0.05):\n",
    "    # Считаем teta с помощью теста и контроля на предпериоде (у них должны быть примерно одинаковые средние, размеры выборок не обязательно равны)\n",
    "    teta = ((np.cov(test, test_before)[0, 1] + np.cov(control, control_before)[0, 1]) \\\n",
    "        / (np.var(test_before) + np.var(control_before)))\n",
    "    \n",
    "    # Считаем новые тест и контроль выборки\n",
    "    new_test = test - teta * test_before\n",
    "    new_control = control - teta * control_before\n",
    "    \n",
    "    return ttest(new_test, new_control, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_bootstrap(control, test, *args, n=3000, alpha=0.05, normed=False):\n",
    "    # Шаг 0. Вычислим длины тестовой и контрольной выборки\n",
    "    M_1 = len(control)\n",
    "    M_2 = len(test)\n",
    "    \n",
    "    # Шаг 1.1. Если нормированный бутстрап, то учтем это.\n",
    "    if normed:\n",
    "        control_before, test_before = args\n",
    "\n",
    "        # Шаг 1.2. Считаем разницу выборочных квантилей у теста и контроля.\n",
    "        effect = test.mean() - (test_before.mean() / control_before.mean()) * control.mean()\n",
    "\n",
    "        # Шаг 1.3. Генерируем индексы\n",
    "        control_indices = np.arange(M_1)\n",
    "        test_indices = np.arange(M_2)\n",
    "        \n",
    "        control_indices_sample = np.random.choice(control_indices, size=(n, M_1), replace=True)\n",
    "        test_indices_sample = np.random.choice(test_indices, size=(n, M_2), replace=True)\n",
    "        \n",
    "        # Шаг 2.1. Генерируем n псевдовыборок из контрольной (и тестовой) группы.\n",
    "        bootstrap_values_c = control[control_indices_sample]\n",
    "        bootstrap_values_t = test[test_indices_sample]\n",
    "\n",
    "        # Шаг 2.2. Генерируем n псевдовыборок из контрольной (и тестовой) группы на предпериоде.\n",
    "        bootstrap_values_c_before = control_before[control_indices_sample]\n",
    "        bootstrap_values_t_before = test_before[test_indices_sample]\n",
    "\n",
    "        # Шаг 2.3. Считаем n выборочных средних у n псевдовыборок из контрольной (тестовой) группы.\n",
    "        bootstrap_metrics_c = np.mean(bootstrap_values_c, axis=1)\n",
    "        bootstrap_metrics_t = np.mean(bootstrap_values_t, axis=1)\n",
    "\n",
    "        # Шаг 2.4. Считаем n выборочных средних у n псевдовыборок из контрольной (тестовой) группы на предпериоде.\n",
    "        bootstrap_metrics_c_before = np.mean(bootstrap_values_c_before, axis=1)\n",
    "        bootstrap_metrics_t_before = np.mean(bootstrap_values_t_before, axis=1)\n",
    "\n",
    "        # Шаг 3. Считаем разницу полученных метрик\n",
    "        bootstrap_stats = bootstrap_metrics_t - (bootstrap_metrics_t_before / bootstrap_metrics_c_before) * bootstrap_metrics_c\n",
    "\n",
    "        # Шаг 4. Строим доверительный интервал методом Центрального бутстрапа.\n",
    "        left = 2 * effect - np.quantile(a=bootstrap_stats, q=1 - alpha / 2)\n",
    "        right = 2 * effect - np.quantile(a=bootstrap_stats, q=alpha / 2)\n",
    "\n",
    "        # Шаг 5. Смотрим ширину доверительного интервала и определяем наличие эффекта.\n",
    "        ci_length = right - left\n",
    "\n",
    "        # Шаг 6. Определяем наличие эффекта\n",
    "        effect_flag = not (left < 0 < right)\n",
    "\n",
    "        return ExperimentComparisonResultsBootstrap(effect_flag, effect, ci_length)\n",
    "    \n",
    "    else:\n",
    "        # Шаг 1.2. Считаем разницу выборочных средних у теста и контроля.\n",
    "        effect = test.mean() - control.mean()\n",
    "\n",
    "        # Шаг 2.1. Генерируем n псевдовыборок из контрольной (и тестовой) группы.\n",
    "        bootstrap_values_c = np.random.choice(control, (n, M_1), replace=True)\n",
    "        bootstrap_values_t = np.random.choice(test, (n, M_2), replace=True)\n",
    "\n",
    "        # Шаг 2.2. Считаем n выборочных средних у n псевдовыборок из контрольной (тестовой) группы .\n",
    "        bootstrap_metrics_c = np.mean(bootstrap_values_c, axis=1)\n",
    "        bootstrap_metrics_t = np.mean(bootstrap_values_t, axis=1)\n",
    "\n",
    "        # Шаг 3. Считаем разницу полученных метрик\n",
    "        bootstrap_stats = bootstrap_metrics_t - bootstrap_metrics_c\n",
    "\n",
    "        # Шаг 4. Строим доверительный интервал методом Центрального бутстрапа.\n",
    "        left = 2 * effect - np.quantile(a=bootstrap_stats, q=1 - alpha / 2)\n",
    "        right = 2 * effect - np.quantile(a=bootstrap_stats, q=alpha / 2)\n",
    "\n",
    "        # Шаг 5. Смотрим ширину доверительного интервала и определяем наличие эффекта.\n",
    "        ci_length = right - left\n",
    "\n",
    "        # Шаг 6. Определяем наличие эффекта\n",
    "        effect_flag = not (left < 0 < right)\n",
    "\n",
    "        return ExperimentComparisonResultsBootstrap(effect_flag, effect, ci_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Реальный достигнутый уровень значимости для T-test: 0.0573\n",
      "Реальный достигнутый уровень значимости для Cuped: 0.048\n",
      "Реальный достигнутый уровень значимости для бутстрапа: 0.0573\n",
      "Реальный достигнутый уровень значимости для нормированного бутстрапа: 0.0547\n",
      "-------------------------------------------------------------------------------\n",
      "Среднее длин доверительных интервалов для T-test: 17.5555\n",
      "Среднее длин доверительных интервалов для Cuped: 0.877\n",
      "Среднее длин доверительных интервалов для бутстрапа: 17.5014\n",
      "Среднее длин доверительных интервалов для нормированного бутстрапа: 1.2396\n"
     ]
    }
   ],
   "source": [
    "ttest_counter_effect = 0\n",
    "cuped_counter_effect = 0\n",
    "central_bootstrap_counter_effect = 0\n",
    "central_normed_bootstrap_counter_effect = 0\n",
    "\n",
    "ttest_ci_length = []\n",
    "cuped_ci_length = []\n",
    "central_bootstrap_ci_length = []\n",
    "central_normed_bootstrap_ci_length = []\n",
    "\n",
    "N = 1500\n",
    "\n",
    "for i in range(N):\n",
    "    control_before = sps.expon.rvs(scale=100, size=1000)\n",
    "    test_before = sps.expon.rvs(scale=100, size=1000)\n",
    "\n",
    "    control = control_before + sps.expon.rvs(scale=5, size=1000)\n",
    "    test = test_before + sps.expon.rvs(scale=5, size=1000)\n",
    "\n",
    "    ttest_result = ttest(test, control)\n",
    "    cuped_result = cuped(control_before, test_before, control, test)\n",
    "    central_bootstrap_result = central_bootstrap(control, test)\n",
    "    central_normed_bootstrap_result = central_bootstrap(control, test, control_before, test_before, normed=True)\n",
    "\n",
    "    ttest_counter_effect += ttest_result.pvalue < 0.05\n",
    "    cuped_counter_effect += cuped_result.pvalue < 0.05\n",
    "    central_bootstrap_counter_effect += central_bootstrap_result.effect_flag\n",
    "    central_normed_bootstrap_counter_effect += central_normed_bootstrap_result.effect_flag\n",
    "\n",
    "    ttest_ci_length.append(ttest_result.ci_length)\n",
    "    cuped_ci_length.append(cuped_result.ci_length)\n",
    "    central_bootstrap_ci_length.append(central_bootstrap_result.ci_length)\n",
    "    central_normed_bootstrap_ci_length.append(central_normed_bootstrap_result.ci_length)\n",
    "\n",
    "print(f\"Реальный достигнутый уровень значимости для T-test: {round(ttest_counter_effect / N, 4)}\",\n",
    "    f\"Реальный достигнутый уровень значимости для Cuped: {round(cuped_counter_effect / N, 4)}\",\n",
    "    f\"Реальный достигнутый уровень значимости для бутстрапа: {round(central_bootstrap_counter_effect / N, 4)}\",\n",
    "    f\"Реальный достигнутый уровень значимости для нормированного бутстрапа: {round(central_normed_bootstrap_counter_effect / N, 4)}\",\n",
    "      sep='\\n')\n",
    "\n",
    "print('-------------------------------------------------------------------------------')\n",
    "\n",
    "print(f\"Среднее длин доверительных интервалов для T-test: {np.array(ttest_ci_length).mean().round(4)}\",\n",
    "    f\"Среднее длин доверительных интервалов для Cuped: {np.array(cuped_ci_length).mean().round(4)}\",\n",
    "    f\"Среднее длин доверительных интервалов для бутстрапа: {np.array(central_bootstrap_ci_length).mean().round(4)}\",\n",
    "    f\"Среднее длин доверительных интервалов для нормированного бутстрапа: {np.array(central_normed_bootstrap_ci_length).mean().round(4)}\",\n",
    "     sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
